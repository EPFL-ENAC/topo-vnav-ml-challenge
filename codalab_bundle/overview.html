<p><span style="font-family: Arial;"><br /> <strong><br /> </strong></span></p>
<h1><span style="font-family: Arial;"><strong>No GPS no problem! Democratising aerial navigation via robust and data-scalable computer vision.</strong></span></h1>
<p style="text-align: center;"><img style="margin-left: -4.079118028534403px; margin-top: 2.0006654285323604e-14px;" src="https://lh3.googleusercontent.com/Jt_kgwhkawPlWMiB672org868ThWHEsmDfDVnOPEZ0JVUXFLXDIfJ0Os94nvVfLTWR_-y9r29_lSDoBi2MWQHBJRbbwOwcmleLSUZbd5iFsRICta9-1kVNZEWILObzjB1c9WzlaF4J8F_1X3qA" alt="" width="633.0791180285344" height="359" /></p>
<p>&nbsp;</p>
<p><span style="font-family: Arial;">Do you believe like us in pushing CV advances in the real world? Will you be a champion in proving CV advances benefits to the world of aviation? Then join us and earn:</span><span style="font-family: Arial;"><br /> </span></p>
<ul>
<li><span style="font-family: Arial;">The prize: <strong style="color: red;">10 000 CHF</strong> (8 000 CHF for 1st place and 2 000 CHF for second) based on the leaderboard ranking. Winners commit to share their solution (git and model explanation report) open source for the benefit of all.</span></li>
</ul>
<ul>
<li><span style="font-family: Arial;">Respect: Being the leader in the real-world challenge of aerial navigation! Leaderboard open for all with no restrictions. </span></li>
</ul>
<p><span style="font-family: Arial;"><br /> The value of research shines best when it touches everyday life! Today's scientific journals in Computer Vision (CV) provide exciting developments that promise a future in which CV systems can automise navigation, control of ground and aerial vehicles. Thus a lasting impact on our daily lives beyond the annals of academic journals. Traditionally, however, academic advancements are focusing on developing theoretical solutions optimised to perform over a given data domain, i.e a set of camera images collected at specific geographic location, trajectory path, camera type, weather, season, date, etc. Those algorithms can rarely be proven to generalise to real-world large-scale applications. Those would require an economically prohibitive amount of training data describing all possible situations and locations in time and space. This poses a challenge to democratisation and realisation of the autonomous/GPS-free promise. As a rising countermeasure, synthetic data and rendering engines have attempted to fill in the data hunger of the CV models (<a href="https://github.com/TOPO-EPFL/TOPO-DataGen">TOPO-DataGen</a> open source example for air nav domain). Two paths exist in bridging the gap between the real scarce data and abundant synthetic: <br /> <br /> </span></p>
<ol>
<li><span style="font-family: Arial;">Either making the synthetic data highly representative of reality or</span></li>
<li><span style="font-family: Arial;">Making models robust to sim-to-real (synthetic data to real data) gap</span></li>
</ol>
<p><br /> <img style="margin-left: 0px; margin-top: 0px;" src="https://lh3.googleusercontent.com/0tlCJnhJptiSDCRjto1s7qe3Zmdo2Y5M2RaNgHFA9CrBZG_fi_1idP8mqoqxWww6xThjsnt1c865e9gLW37aEmzmZ8JwEtsuCNV_aXAR69zoR_p6G9CPad9PUHoREROLi-AdEMWO5YE-EQL9YA" alt="" width="527" height="342" /></p>
<address><em><span style="font-family: Arial;">Through the Looking-Glass, Alice Pushes Through the Mirror (between real and synthetic data) - drawn by John Tenniel, 1872</span></em></address>
<p><span style="font-family: Arial;"><br /> We believe that the real-challenge of today's CV is to develop and validate a design philosophy for algorithms that can work robustly and in an economically/data scalable way. In other words:<br /> </span></p>
<ul>
<li><span style="font-family: Arial;">Being able to train with limited or even no real/domain specific data (zero-shot). Those leveraging synthetic data generated by open source tools such as <a href="https://github.com/TOPO-EPFL/TOPO-DataGen">TOPO-DataGen</a>.</span></li>
<li><span style="font-family: Arial;">Capable of producing accurate output with trustworthy uncertainty statements that can capture accurately the prediction errors. [4]</span></li>
</ul>
<p><span style="font-family: Arial;"><br /> </span></p>
<p>&nbsp;</p>
<h2><span style="font-family: Arial;"><strong>The challenge, should you choose to accept it.</strong></span></h2>
<h2>&nbsp;</h2>
<p><span style="font-family: Arial;">Today aerial autonomous systems for navigation and control are heavily dependent on the robustness of GNSS reception. Lack of thereof (terrain, weather, or adversarial spoofing) can lead to loss of autonomous system absolute orientation. This in the medium to long run (error will always accumulate in time with dead reckoning) can be unsafe for operation, especially on beyond line of sight missions. Despite significant progress in Computer Vision, most learning-based approaches target a single domain and require a dense database of geo-tagged images to function well. Or at least a calibration set of real images taken closely from the domain of [1,2] operation. Several industry attempts are made in the same direction, however, understandably without an official benchmark or validation.</span></p>
<p>&nbsp;</p>
<p><img style="margin-left: 0px; margin-top: 0px;" src="https://lh6.googleusercontent.com/DhS-jaBBTRywlgF9fjzA3lDhKPiQ8nAQ4ELrxySrMX9qObxiN889t1gvw7Cg5gnFfnTi6D9XrAQs0Fh7wsew3Mbv8y7lhHyTPMgVSO7oy6Jje9itEPen5OtTrAers_ALz-Szg6NDRKtskDzcSA" alt="" width="668" height="160" /></p>
<p><span style="font-family: Arial;"><br /> We challenge you to prove your approach can work <strong>robustly </strong>and in an<strong> economically/data scalable way</strong>. To do this by proving you can compute accurate 6D camera poses with known uncertainty on our challenge validation dataset. To do this by having only access to:<br /> </span></p>